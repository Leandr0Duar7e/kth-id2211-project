\documentclass[11pt]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{titlesec}
\usepackage{cite}

% Define KTH colors
\definecolor{kthblue}{RGB}{25,84,166}
\definecolor{kthgray}{RGB}{229,229,229}

% Set margins
\geometry{margin=0.75in}

% Configure list spacing
\setlist{noitemsep}
\setlist[itemize]{leftmargin=*}

% Configure section formatting
\titleformat{\section}{\normalfont\bfseries\color{kthblue}}{\thesection.}{0.5em}{}
\titlespacing{\section}{0pt}{5pt}{1pt}
\titleformat*{\subsection}{\normalfont\small\bfseries\color{kthblue}}

% Create commands for section titles without numbers
\newcommand{\propitem}[1]{\noindent{\textbf{\color{kthblue}#1:} }}

\begin{document}

\begin{center}
\Large{\textbf{Project Proposal}}\\
\normalsize{\textbf{ID2211 - Data Mining}}\\[0.3cm]
\end{center}

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}

\begin{center}
\textbf{Miguel Arroyo Marquez, Mingyang Chen, Leandro Duarte, Andrei Iliescu}
\end{center}

\vspace{0.2cm}

\propitem{Project Title} Temporal Evolution of Political Communities on Reddit: A Graph-Based Analysis

\propitem{Problem Statement} We aim to understand how political communities on Reddit form, change, and dissolve over time (2008-2019). We want to see if big political events like elections cause these communities to change their structure. We will track how groups of political subreddits cluster together based on shared users, and measure if these clusters become more separate (polarized) over time. This analysis will help us understand how online political discussion spaces react to real-world events.

\propitem{Data} We will use the Reddit Politosphere dataset ~\cite{Hofmann_Sch√ºtze_Pierrehumbert_2022}, a large-scale resource of online political discourse covering more than 600 political subreddits over a 12-year period (2008-2019). This dataset contains two primary types of information for each year:

\begin{enumerate}
    \item \textbf{Network data files} (networks\_YYYY.csv): These files contain weighted and unweighted network representations where nodes are subreddits and edges represent user overlap between them. Edge weights correspond to the number of users who posted at least 10 comments in both subreddits. The unweighted networks are derived using statistical network backboning techniques to filter out noise while preserving significant connections.
    
    \item \textbf{Comment data files} (comments\_YYYY-MM.bz2): These contain all comments posted in the political subreddits along with metadata such as creation time, author (pseudonymized), and other attributes. The dataset includes over 288 million comments across all years.
\end{enumerate}

The dataset also provides valuable metadata for both subreddits and users. Subreddit metadata includes information about banned status, political affiliation (democratic/republican), and regional focus. User metadata, while preserving anonymity through pseudonymization, contains information about user types (e.g., bots, automoderators) and certain linguistic patterns in usernames.

\propitem{Work Plan} Our work will progress through these main steps:
\begin{enumerate}
    \item \textbf{Data preparation}: Load the yearly network files and preprocess them to ensure they are ready for analysis.
    \item \textbf{Community detection}: Apply algorithms to find clusters of related subreddits for each year.
    \item \textbf{Temporal analysis}: Track how identified communities change from year to year.
    \item \textbf{Event correlation}: Create a timeline of major political events and check if they match with community changes.
    \item \textbf{Analysis and visualization}: Calculate metrics about community structure and create visualizations showing how communities evolved.
    \item \textbf{Report preparation}: Document our methods, results, and conclusions.
\end{enumerate}

\propitem{Methodology} We will implement multiple community detection algorithms from the course to analyze the networks:

\begin{enumerate}
    \item \textbf{Label Propagation Algorithm} (from Lecture 8): A simple algorithm where nodes adopt the most common label among their neighbors. It's fast and scales well to large networks.
    
    \item \textbf{Spectral Clustering} (from Lecture 9): We will construct the graph Laplacian matrix, find its eigenvalues and eigenvectors, and use the eigengap heuristic to determine the optimal number of communities.
    
    \item \textbf{Optionally: Louvain Method}: This algorithm tries to maximize modularity by iteratively moving nodes between communities.
\end{enumerate}

For tracking communities over time, we will calculate the Jaccard similarity index between communities in consecutive years (e.g., 2008 and 2009). This tells us how much overlap exists between communities across years. We will say a community "continues" if its overlap with a community in the next year is above a certain threshold.

\propitem{Evaluation} We will evaluate our analysis in several ways:

\begin{enumerate}
    \item \textbf{Community quality}: We will use modularity (Q) scores to measure how well-defined our detected communities are. Higher modularity means better separation between communities.
    
    \item \textbf{Temporal correlation}: We will check if significant changes in community structure happen around major political events like elections. We will measure the time distance between events and community shifts.
    
    \item \textbf{Validation with metadata}: We will compare our detected communities with the known political affiliations of subreddits (from metadata) to see if our algorithms correctly group similar subreddits.
    
    \item \textbf{Algorithm comparison}: We will compare results from different community detection methods to ensure our findings are not just artifacts of one algorithm.
\end{enumerate}

\propitem{Expected Outcomes} By the end of the project, we expect to deliver:

\begin{enumerate}
    \item An analysis of how political communities on Reddit evolved over the 12-year period.
    \item Evidence of whether political events cause measurable changes in online community structure.
    \item Measurements of political polarization trends over time (whether communities became more or less separate).
    \item Visualizations showing the evolution of communities and their responses to events.
    \item Comparison of different community detection algorithms in their ability to track political communities.
    \item Code that implements our methodology so others can reproduce our results.
\end{enumerate}

\propitem{Timeline}
\begin{itemize}
    \item \textbf{Week 1}: Data collection and preprocessing; Set up development environment; Initial exploration of network structure
    \item \textbf{Week 2}: Implement and run community detection algorithms (Label Propagation and Spectral Clustering); Start temporal tracking implementation
    \item \textbf{Week 3}: Complete temporal tracking; Collect political event timeline; Begin correlation analysis and visualization
    \item \textbf{Week 4}: Finalize analysis; Generate all visualizations; Prepare final report and presentation
\end{itemize}

\bibliographystyle{myIEEEtran}
\bibliography{dm_project_proposal}

\vspace{0.2cm}
\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}
\begin{center}
\small{KTH Royal Institute of Technology}
\end{center}

\end{document}
